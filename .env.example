# =============================================================================
# ELK Stack Environment Configuration
# =============================================================================
#
# IMPORTANT: This is a template file. Copy this file to .env and set actual values.
#
# DO NOT commit .env to version control!
# DO NOT use these example values in production!
#
# To generate secure random passwords, run:
#   ./scripts/generate-secrets.sh
#
# =============================================================================

# -----------------------------------------------------------------------------
# ElasticSearch Configuration
# -----------------------------------------------------------------------------

# ElasticSearch version
ELASTIC_VERSION=8.11.3

# ElasticSearch password for 'elastic' superuser
# Generate with: openssl rand -base64 32
ELASTIC_PASSWORD=CHANGE_ME_PLEASE

# ElasticSearch cluster name
ELASTIC_CLUSTER_NAME=elk-cluster

# ElasticSearch node name
NODE_NAME=elasticsearch

# Discovery type (single-node for standalone, multi-node for cluster)
DISCOVERY_TYPE=single-node

# ElasticSearch heap size (50% of available RAM, max 32GB)
# Examples: 2g, 4g, 8g, 16g
ES_JAVA_OPTS=-Xms2g -Xmx2g

# ElasticSearch ports
ELASTIC_PORT=9200
ELASTIC_NODE_PORT=9300

# -----------------------------------------------------------------------------
# Kibana Configuration
# -----------------------------------------------------------------------------

# Kibana system user password (used for internal communication with ElasticSearch)
# Generate with: openssl rand -base64 32
KIBANA_PASSWORD=CHANGE_ME_PLEASE

# Kibana encryption keys (must be at least 32 characters)
# Generate with: openssl rand -base64 48
KIBANA_ENCRYPTION_KEY=CHANGE_ME_PLEASE_MINIMUM_32_CHARACTERS_REQUIRED
KIBANA_REPORTING_ENCRYPTION_KEY=CHANGE_ME_PLEASE_MINIMUM_32_CHARACTERS_REQUIRED

# Kibana port
KIBANA_PORT=5601

# -----------------------------------------------------------------------------
# Logstash Configuration
# -----------------------------------------------------------------------------

# Logstash heap size
# Examples: 256m, 512m, 1g, 2g
LS_JAVA_OPTS=-Xms1g -Xmx1g

# Logstash ports
LOGSTASH_BEATS_PORT=5044
LOGSTASH_TCP_PORT=5000
LOGSTASH_API_PORT=9600

# -----------------------------------------------------------------------------
# APISIX Configuration
# -----------------------------------------------------------------------------

# APISIX Admin API key (for managing routes and configurations)
# Generate with: openssl rand -hex 32
APISIX_ADMIN_KEY=CHANGE_ME_PLEASE

# APISIX Dashboard admin password
# Generate with: openssl rand -base64 32
APISIX_DASHBOARD_PASSWORD=CHANGE_ME_PLEASE

# -----------------------------------------------------------------------------
# Grafana Configuration
# -----------------------------------------------------------------------------

# Grafana admin user password
# Minimum 8 characters
GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=CHANGE_ME_PLEASE

# Grafana secret key (for signing cookies and data sources)
# Generate with: openssl rand -base64 32
GRAFANA_SECRET_KEY=CHANGE_ME_PLEASE

# -----------------------------------------------------------------------------
# APM Server Configuration
# -----------------------------------------------------------------------------

# APM Server secret token (optional, for client authentication)
# Generate with: openssl rand -base64 32
APM_SECRET_TOKEN=

# -----------------------------------------------------------------------------
# Alertmanager Configuration (Optional)
# -----------------------------------------------------------------------------

# SMTP password for email alerts
SMTP_PASSWORD=

# PagerDuty service key
PAGERDUTY_SERVICE_KEY=

# Slack webhook URL
SLACK_WEBHOOK_URL=

# -----------------------------------------------------------------------------
# Client/Deployment Information
# -----------------------------------------------------------------------------

# Client name (used for tenant identification and resource tagging)
CLIENT_NAME=default-client

# Deployment environment
# Values: development, staging, production
ENVIRONMENT=development

# Log retention period in days
RETENTION_DAYS=90

# Expected daily log volume in GB (for capacity planning)
LOG_VOLUME_GB_PER_DAY=10

# -----------------------------------------------------------------------------
# Network Configuration
# -----------------------------------------------------------------------------

# Public hostname or IP for external access
# Used for SSL certificates and external integrations
PUBLIC_HOSTNAME=localhost

# -----------------------------------------------------------------------------
# SSL/TLS Configuration
# -----------------------------------------------------------------------------

# Enable SSL/TLS (true/false)
# When enabled, ensure certificates are generated in ./certs directory
ENABLE_SSL=false
XPACK_SECURITY_ENABLED=true
XPACK_SECURITY_HTTP_SSL_ENABLED=false
XPACK_SECURITY_TRANSPORT_SSL_ENABLED=false

# Certificate paths (relative to project root)
CERT_DIR=./certs

# -----------------------------------------------------------------------------
# Backup Configuration
# -----------------------------------------------------------------------------

# Enable automated backups (true/false)
BACKUP_ENABLED=true

# Backup schedule (cron expression)
# Examples:
#   0 2 * * *        = Daily at 2:00 AM
#   0 */6 * * *      = Every 6 hours
#   0 0 * * 0        = Weekly on Sunday at midnight
#   0 3 */2 * *      = Every 2 days at 3:00 AM
BACKUP_SCHEDULE=0 2 * * *

# Snapshot repository type
# Options: fs (filesystem), s3 (AWS S3), azure (Azure Blob), gcs (Google Cloud Storage)
BACKUP_REPOSITORY_TYPE=fs

# Snapshot repository name (shown in ElasticSearch)
BACKUP_REPOSITORY_NAME=backup-repo

# Filesystem backup location (used when BACKUP_REPOSITORY_TYPE=fs)
# Must be mounted as a Docker volume
SNAPSHOT_REPOSITORY_PATH=/mnt/elasticsearch-backups

# Backup retention in days (snapshots older than this will be deleted)
BACKUP_RETENTION_DAYS=30

# Maximum number of snapshots to retain (regardless of age)
# Should match BACKUP_RETENTION_DAYS for daily backups (one snapshot per day)
BACKUP_MAX_COUNT=30

# Compress snapshots (true/false) - reduces storage but increases CPU usage
BACKUP_COMPRESS=true

# Backup mode (what indices to include in each snapshot)
# Options:
#   daily                 = Only today's indices (recommended - compartmentalized, independent snapshots)
#                           Each snapshot is self-contained and can be deleted without affecting others
#   *                     = All indices (legacy - creates interdependent snapshots)
#                           Deleting old snapshots may not free much space
#   mule-logs-*           = Custom pattern - only Mule logs
#   mule-logs-*,logstash-* = Custom pattern - Mule and Logstash logs
BACKUP_INDICES=daily

# Exclude indices pattern (comma-separated, supports wildcards)
# Useful for excluding system indices or temporary data
BACKUP_EXCLUDE_INDICES=.monitoring-*,.watcher-*,.security-*

# Verify snapshots after creation (true/false)
# Increases backup time but ensures data integrity
BACKUP_VERIFY=true

# Send backup status notifications (true/false)
BACKUP_NOTIFICATIONS_ENABLED=false

# Notification webhook URL (e.g., Slack, Discord, custom endpoint)
BACKUP_WEBHOOK_URL=

# -----------------------------------------------------------------------------
# AWS S3 Backup Configuration (when BACKUP_REPOSITORY_TYPE=s3)
# -----------------------------------------------------------------------------

# AWS S3 bucket name
AWS_S3_BUCKET=

# AWS S3 region
AWS_S3_REGION=us-east-1

# AWS S3 base path (optional, for organizing backups in bucket)
AWS_S3_BASE_PATH=elasticsearch-backups

# AWS Access credentials
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=

# S3 storage class (STANDARD, STANDARD_IA, GLACIER, etc.)
AWS_S3_STORAGE_CLASS=STANDARD_IA

# -----------------------------------------------------------------------------
# Azure Blob Backup Configuration (when BACKUP_REPOSITORY_TYPE=azure)
# -----------------------------------------------------------------------------

# Azure storage account name
AZURE_STORAGE_ACCOUNT=

# Azure storage account key
AZURE_STORAGE_KEY=

# Azure container name
AZURE_CONTAINER=elasticsearch-backups

# Azure base path (optional)
AZURE_BASE_PATH=

# -----------------------------------------------------------------------------
# Google Cloud Storage Backup Configuration (when BACKUP_REPOSITORY_TYPE=gcs)
# -----------------------------------------------------------------------------

# GCS bucket name
GCS_BUCKET=

# GCS base path (optional)
GCS_BASE_PATH=elasticsearch-backups

# GCS service account credentials file path (JSON key file)
GCS_CREDENTIALS_FILE=/path/to/service-account-key.json

# -----------------------------------------------------------------------------
# Index Lifecycle Management (ILM) - Log Retention Configuration
# -----------------------------------------------------------------------------

# Enable automatic log retention policies
ILM_ENABLED=true

# Mule logs retention period (in days)
# How long to keep Mule application logs before automatic deletion
# Examples:
#   30   = 1 month
#   90   = 3 months
#   365  = 1 year
#   730  = 2 years (default)
MULE_LOGS_RETENTION_DAYS=730

# Logstash logs retention period (in days)
# How long to keep general Logstash logs before automatic deletion
LOGSTASH_LOGS_RETENTION_DAYS=730

# Index rollover size threshold
# Indices will rollover when reaching this size OR daily (whichever comes first)
# Examples:
#   500mb = 500 megabytes
#   1gb   = 1 gigabyte (default)
#   5gb   = 5 gigabytes
#   10gb  = 10 gigabytes
ROLLOVER_SIZE=1gb

# Index rollover age threshold
# Maximum age before index rollover (in addition to size threshold)
# Format: 1d (1 day), 7d (7 days), 1h (1 hour)
ROLLOVER_MAX_AGE=1d

# ILM poll interval
# How often ElasticSearch checks for ILM actions (default: 10m)
# Format: 1m (1 minute), 10m (10 minutes), 1h (1 hour)
ILM_POLL_INTERVAL=10m

# -----------------------------------------------------------------------------
# Monitoring and Alerting Configuration
# -----------------------------------------------------------------------------

# Enable Prometheus metrics collection (true/false)
# When enabled, Prometheus scrapes metrics from all services
# Includes Prometheus, Grafana dashboards, and ElasticSearch exporter
MONITORING_ENABLED=true

# Enable Alertmanager for alert notifications (true/false)
# Requires MONITORING_ENABLED=true
# When disabled, alerts are evaluated but not sent to notification channels
ALERTING_ENABLED=false

# Prometheus Configuration
# Metrics retention period (default: 30d)
PROMETHEUS_RETENTION=30d

# Scrape interval for metrics collection
PROMETHEUS_SCRAPE_INTERVAL=15s

# Evaluation interval for alert rules
PROMETHEUS_EVALUATION_INTERVAL=15s

# ElasticSearch Exporter Configuration
# Enable ElasticSearch metrics exporter (true/false)
ELASTICSEARCH_EXPORTER_ENABLED=false

# Logstash metrics collection (uses built-in monitoring API)
LOGSTASH_MONITORING_ENABLED=false

# Alert Thresholds
# ElasticSearch cluster health alert (values: green, yellow, red)
ALERT_ES_CLUSTER_STATUS=yellow

# Disk space usage threshold (percentage, 0-100)
ALERT_DISK_USAGE_THRESHOLD=85

# Memory usage threshold (percentage, 0-100)
ALERT_MEMORY_USAGE_THRESHOLD=90

# JVM heap usage threshold (percentage, 0-100)
ALERT_JVM_HEAP_THRESHOLD=90

# Index health check interval (duration: 5m, 10m, 1h)
ALERT_INDEX_CHECK_INTERVAL=10m

# Service down alert duration (how long before alerting)
ALERT_SERVICE_DOWN_DURATION=5m

# High request latency threshold (milliseconds)
ALERT_REQUEST_LATENCY_MS=1000

# Failed backup alert (true/false)
ALERT_ON_FAILED_BACKUP=true

# Email Alert Configuration (SMTP)
# Enable email alerts (true/false)
ALERT_EMAIL_ENABLED=false

# SMTP server configuration
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=
SMTP_PASSWORD=
SMTP_FROM_ADDRESS=alerts@example.com
SMTP_TO_ADDRESSES=admin@example.com,ops@example.com

# Use TLS for SMTP (true/false)
SMTP_USE_TLS=true

# Slack Alert Configuration
# Enable Slack notifications (true/false)
ALERT_SLACK_ENABLED=false

# Slack webhook URL
SLACK_WEBHOOK_URL=

# Slack channel for alerts (e.g., #alerts, #monitoring)
SLACK_CHANNEL=#alerts

# Slack username for bot
SLACK_USERNAME=ELK-Alertmanager

# PagerDuty Alert Configuration
# Enable PagerDuty integration (true/false)
ALERT_PAGERDUTY_ENABLED=false

# PagerDuty integration key (also called routing key or service key)
PAGERDUTY_INTEGRATION_KEY=

# PagerDuty severity levels
# critical, error, warning, info
PAGERDUTY_SEVERITY=error

# Webhook Alert Configuration
# Enable generic webhook notifications (true/false)
ALERT_WEBHOOK_ENABLED=false

# Webhook URL for custom integrations
ALERT_WEBHOOK_URL=

# Webhook HTTP method (POST, PUT)
ALERT_WEBHOOK_METHOD=POST

# Webhook timeout (seconds)
ALERT_WEBHOOK_TIMEOUT=10

# Alert Grouping and Throttling
# Group alerts by labels (comma-separated)
ALERT_GROUP_BY=alertname,cluster,service

# Wait time before sending initial notification
ALERT_GROUP_WAIT=30s

# Wait time before sending notification about new alerts in group
ALERT_GROUP_INTERVAL=5m

# Minimum time between repeat notifications
ALERT_REPEAT_INTERVAL=4h

# Alertmanager Configuration
# Alertmanager data retention (default: 120h)
ALERTMANAGER_RETENTION=120h

# Alertmanager external URL (for links in notifications)
ALERTMANAGER_EXTERNAL_URL=http://localhost:9080/alertmanager

# Dashboard URLs (for alert context)
GRAFANA_EXTERNAL_URL=http://localhost:9080/grafana
KIBANA_EXTERNAL_URL=http://localhost:9080/kibana

# -----------------------------------------------------------------------------
# SSL/TLS Configuration
# -----------------------------------------------------------------------------

# Enable SSL/TLS for all services (default: false)
# When enabled, services use HTTPS/TLS instead of HTTP
SSL_ENABLED=false

# SSL/TLS Domain (for Let's Encrypt and certificate generation)
SSL_DOMAIN=localhost

# Certificate paths (relative to project root)
SSL_CERTS_DIR=./certs

# -----------------------------------------------------------------------------
# ElasticSearch SSL/TLS
# -----------------------------------------------------------------------------

# Enable ElasticSearch HTTPS (REST API)
ELASTICSEARCH_SSL_ENABLED=${SSL_ENABLED}

# Enable ElasticSearch Transport SSL (node-to-node communication)
ELASTICSEARCH_TRANSPORT_SSL_ENABLED=${SSL_ENABLED}

# ElasticSearch certificate paths
ELASTICSEARCH_SSL_CERTIFICATE=${SSL_CERTS_DIR}/elasticsearch/elasticsearch.crt
ELASTICSEARCH_SSL_KEY=${SSL_CERTS_DIR}/elasticsearch/elasticsearch.key
ELASTICSEARCH_SSL_CA=${SSL_CERTS_DIR}/ca/ca.crt

# ElasticSearch SSL verification mode (full, certificate, none)
# - full: Verify hostname and certificate (recommended for production)
# - certificate: Verify certificate only
# - none: No verification (not recommended for production)
ELASTICSEARCH_SSL_VERIFICATION_MODE=full

# PKCS#12 keystore password (if using .p12 format)
ELASTICSEARCH_KEYSTORE_PASSWORD=changeit

# -----------------------------------------------------------------------------
# Kibana SSL/TLS
# -----------------------------------------------------------------------------

# Enable Kibana HTTPS
KIBANA_SSL_ENABLED=${SSL_ENABLED}

# Kibana certificate paths
KIBANA_SSL_CERTIFICATE=${SSL_CERTS_DIR}/kibana/kibana.crt
KIBANA_SSL_KEY=${SSL_CERTS_DIR}/kibana/kibana.key

# Kibana -> ElasticSearch SSL settings
KIBANA_ELASTICSEARCH_SSL_CA=${SSL_CERTS_DIR}/ca/ca.crt
KIBANA_ELASTICSEARCH_SSL_VERIFICATION_MODE=full

# -----------------------------------------------------------------------------
# Logstash SSL/TLS
# -----------------------------------------------------------------------------

# Enable Logstash SSL/TLS
LOGSTASH_SSL_ENABLED=${SSL_ENABLED}

# Logstash certificate paths
LOGSTASH_SSL_CERTIFICATE=${SSL_CERTS_DIR}/logstash/logstash.crt
LOGSTASH_SSL_KEY=${SSL_CERTS_DIR}/logstash/logstash.key

# Logstash -> ElasticSearch SSL settings
LOGSTASH_ELASTICSEARCH_SSL_CA=${SSL_CERTS_DIR}/ca/ca.crt
LOGSTASH_ELASTICSEARCH_SSL_VERIFICATION=true

# Logstash Beats input SSL (port 5044)
LOGSTASH_BEATS_SSL_ENABLED=${SSL_ENABLED}
LOGSTASH_BEATS_SSL_CERTIFICATE=${SSL_CERTS_DIR}/logstash/logstash.crt
LOGSTASH_BEATS_SSL_KEY=${SSL_CERTS_DIR}/logstash/logstash.key
LOGSTASH_BEATS_SSL_VERIFICATION_MODE=none

# -----------------------------------------------------------------------------
# APISIX SSL/TLS (API Gateway)
# -----------------------------------------------------------------------------

# Enable APISIX HTTPS (port 9443)
APISIX_SSL_ENABLED=${SSL_ENABLED}

# APISIX certificate paths
APISIX_SSL_CERTIFICATE=${SSL_CERTS_DIR}/apisix/apisix.crt
APISIX_SSL_KEY=${SSL_CERTS_DIR}/apisix/apisix.key

# APISIX SSL protocols (TLSv1.2, TLSv1.3)
APISIX_SSL_PROTOCOLS=TLSv1.2 TLSv1.3

# APISIX SSL ciphers (leave empty for default secure ciphers)
APISIX_SSL_CIPHERS=

# Force HTTPS redirect (redirect HTTP to HTTPS)
APISIX_FORCE_HTTPS=false

# HSTS (HTTP Strict Transport Security) settings
APISIX_HSTS_ENABLED=false
APISIX_HSTS_MAX_AGE=31536000
APISIX_HSTS_INCLUDE_SUBDOMAINS=true

# -----------------------------------------------------------------------------
# Prometheus SSL/TLS
# -----------------------------------------------------------------------------

# Enable Prometheus HTTPS
PROMETHEUS_SSL_ENABLED=${SSL_ENABLED}

# Prometheus certificate paths
PROMETHEUS_SSL_CERTIFICATE=${SSL_CERTS_DIR}/prometheus/prometheus.crt
PROMETHEUS_SSL_KEY=${SSL_CERTS_DIR}/prometheus/prometheus.key

# Prometheus web config file (for SSL/TLS and basic auth)
PROMETHEUS_WEB_CONFIG=/etc/prometheus/web-config.yml

# -----------------------------------------------------------------------------
# Grafana SSL/TLS
# -----------------------------------------------------------------------------

# Enable Grafana HTTPS
GRAFANA_SSL_ENABLED=${SSL_ENABLED}

# Grafana certificate paths
GRAFANA_SSL_CERTIFICATE=${SSL_CERTS_DIR}/grafana/grafana.crt
GRAFANA_SSL_KEY=${SSL_CERTS_DIR}/grafana/grafana.key

# Grafana SSL protocols (leave empty for default)
GRAFANA_SSL_PROTOCOLS=

# Grafana SSL ciphers (leave empty for default)
GRAFANA_SSL_CIPHERS=

# -----------------------------------------------------------------------------
# Alertmanager SSL/TLS
# -----------------------------------------------------------------------------

# Enable Alertmanager HTTPS
ALERTMANAGER_SSL_ENABLED=${SSL_ENABLED}

# Alertmanager certificate paths
ALERTMANAGER_SSL_CERTIFICATE=${SSL_CERTS_DIR}/alertmanager/alertmanager.crt
ALERTMANAGER_SSL_KEY=${SSL_CERTS_DIR}/alertmanager/alertmanager.key

# -----------------------------------------------------------------------------
# APM Server SSL/TLS
# -----------------------------------------------------------------------------

# Enable APM Server HTTPS
APM_SERVER_SSL_ENABLED=${SSL_ENABLED}

# APM Server certificate paths
APM_SERVER_SSL_CERTIFICATE=${SSL_CERTS_DIR}/apm-server/apm-server.crt
APM_SERVER_SSL_KEY=${SSL_CERTS_DIR}/apm-server/apm-server.key

# APM Server -> ElasticSearch SSL
APM_SERVER_ELASTICSEARCH_SSL_CA=${SSL_CERTS_DIR}/ca/ca.crt
APM_SERVER_ELASTICSEARCH_SSL_VERIFICATION=true

# -----------------------------------------------------------------------------
# Let's Encrypt Configuration (Production)
# -----------------------------------------------------------------------------

# Enable Let's Encrypt automatic certificate management
LETSENCRYPT_ENABLED=false

# Let's Encrypt email for notifications
LETSENCRYPT_EMAIL=

# Let's Encrypt staging server (for testing)
LETSENCRYPT_STAGING=false

# Let's Encrypt renewal method (standalone, webroot, dns)
LETSENCRYPT_RENEWAL_METHOD=standalone

# Webroot path (if using webroot method)
LETSENCRYPT_WEBROOT_PATH=/var/www/html

# Automatic renewal (via cron)
LETSENCRYPT_AUTO_RENEW=true

# -----------------------------------------------------------------------------
# Advanced Configuration
# -----------------------------------------------------------------------------

# ElasticSearch node count (for clustering)
ES_NODE_COUNT=1

# Enable debug logging
DEBUG=false

# -----------------------------------------------------------------------------
# Notes
# -----------------------------------------------------------------------------
#
# After copying this file to .env and setting values:
#
# 1. Generate secure passwords:
#    ./scripts/generate-secrets.sh
#
# 2. Review and customize settings based on your deployment:
#    - Memory allocation (ES_JAVA_OPTS, LS_JAVA_OPTS)
#    - Retention periods (RETENTION_DAYS, BACKUP_RETENTION_DAYS)
#    - Client information (CLIENT_NAME, ENVIRONMENT)
#
# 3. For production deployments:
#    - Set ENABLE_SSL=true and XPACK_SECURITY_HTTP_SSL_ENABLED=true
#    - Generate SSL certificates: ./certs/generate-certs.sh
#    - Configure external hostname: PUBLIC_HOSTNAME
#    - Enable monitoring: ENABLE_MONITORING=true
#    - Configure alerting (SMTP, PagerDuty, Slack)
#
# 4. Protect the .env file:
#    chmod 600 .env
#
# =============================================================================
