input {
  # Beats input (Filebeat, Metricbeat, etc.)
  beats {
    port => 5044
  }

  # TCP input
  tcp {
    port => 5000
    codec => json
  }

  # UDP input
  udp {
    port => 5000
    codec => json
  }

  # HTTP input for testing
  # Example: curl -XPOST 'http://localhost:8080' -d '{"message":"hello world"}'
  # Uncomment to enable:
  # http {
  #   port => 8080
  # }
}

filter {
  # ============================================
  # AUTHENTICATION: Validate auth token
  # ============================================
  # Check if auth_token field exists and matches expected token
  if [auth_token] {
    # Validate token
    if [auth_token] != "${LOGSTASH_AUTH_TOKEN}" {
      # Authentication failed - tag and drop the event
      mutate {
        add_tag => ["auth_failed", "unauthorized"]
        add_field => { "[@metadata][auth_status]" => "failed" }
      }
      # Drop unauthorized logs
      drop { }
    } else {
      # Authentication successful - tag and remove token from logs
      mutate {
        add_tag => ["authenticated"]
        add_field => { "[@metadata][auth_status]" => "success" }
      }
      # Remove auth_token from stored logs for security
      mutate {
        remove_field => ["auth_token"]
      }
    }
  } else {
    # No auth_token provided - tag as unauthenticated
    mutate {
      add_tag => ["no_auth_token", "unauthenticated"]
      add_field => { "[@metadata][auth_status]" => "missing_token" }
    }
    # Drop logs without auth token
    drop { }
  }

  # ============================================
  # Log Processing (only authenticated logs reach here)
  # ============================================
  # Detect Mule application logs and set appropriate index
  if [log_type] == "mule" or [application] {
    mutate {
      add_field => {
        "[@metadata][target_index]" => "mule-logs-%{+YYYY.MM.dd}"
      }
      add_tag => ["mule"]
    }
  } else {
    mutate {
      add_field => {
        "[@metadata][target_index]" => "logstash-%{+YYYY.MM.dd}"
      }
    }
  }

  # Parse JSON if the message is JSON string
  if [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
      target => "parsed"
    }
    # Promote parsed fields to root level
    ruby {
      code => "
        parsed = event.get('parsed')
        if parsed.is_a?(Hash)
          parsed.each { |k, v| event.set(k, v) }
          event.remove('parsed')
        end
      "
    }
  }

  # Parse log4j2 timestamp if present
  if [timeMillis] {
    date {
      match => ["timeMillis", "UNIX_MS"]
      target => "@timestamp"
    }
  }

  # Add geolocation if IP is present (optional)
  if [host] {
    mutate {
      rename => { "host" => "source_host" }
    }
  }

  # Add timestamp if not present
  if ![timestamp] and ![@timestamp] {
    ruby {
      code => "event.set('timestamp', Time.now.utc)"
    }
  }

  # Remove unnecessary fields
  mutate {
    remove_field => ["timeMillis", "endOfBatch", "loggerFqcn"]
  }
}

output {
  # Output to ElasticSearch
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "%{[@metadata][target_index]}"
    user => "elastic"
    password => "${ELASTIC_PASSWORD}"
  }

  # Output to stdout for debugging (comment out in production)
  stdout {
    codec => rubydebug
  }
}
